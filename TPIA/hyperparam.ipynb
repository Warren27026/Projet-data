{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc037d-4e7b-4595-8386-587f34733206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bootstrap_confidence_interval(model, x_test, y_test, metric, n_bootstrap=1000, alpha=0.05):\n",
    "    scores = []\n",
    "    x_test = np.array(x_test)  # Conversion en tableau NumPy\n",
    "    y_test = np.array(y_test)  # Conversion en tableau NumPy\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = resample(np.arange(len(x_test)), replace=True)\n",
    "        x_sample = x_test[indices]\n",
    "        y_sample = y_test[indices]\n",
    "        y_pred = model.predict(x_sample)\n",
    "        score = metric(y_sample, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    lower_bound = np.percentile(scores, alpha / 2 * 100)\n",
    "    upper_bound = np.percentile(scores, (1 - alpha / 2) * 100)\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "def evaluate_model(model, x_train, y_train, x_dev, y_dev, metric_func, additional_params=None):\n",
    "    if additional_params:\n",
    "        model.set_params(**additional_params)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_dev = np.array(x_dev)\n",
    "    y_dev = np.array(y_dev)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    y_pred = model.predict(x_dev)\n",
    "    accuracy = accuracy_score(y_dev, y_pred)\n",
    "    f1 = f1_score(y_dev, y_pred, average='weighted')\n",
    "    confidence_interval = bootstrap_confidence_interval(model, x_test, y_test, metric_func)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Time (s)\": train_time,\n",
    "        \"Confidence Interval\": confidence_interval,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3879a9a-e1ac-4dce-a5c6-0510df8ab52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_confidence_interval(model, x_test, y_test, metric, n_bootstrap=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calcule un intervalle de confiance pour une métrique donnée en utilisant le bootstrap.\n",
    "    \n",
    "    :param model: Le modèle entraîné\n",
    "    :param x_test: Les données de test\n",
    "    :param y_test: Les labels de test\n",
    "    :param metric: Fonction pour calculer la métrique (par ex. accuracy_score)\n",
    "    :param n_bootstrap: Nombre d'échantillons bootstrap\n",
    "    :param alpha: Niveau de confiance (par défaut 95%)\n",
    "    :return: Tuple contenant les bornes inférieure et supérieure de l'intervalle de confiance\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Générer des indices bootstrap\n",
    "        indices = resample(np.arange(len(x_test)), replace=True)\n",
    "        x_sample = x_test[indices]\n",
    "        y_sample = y_test[indices]\n",
    "        # Prédire et calculer la métrique\n",
    "        y_pred = model.predict(x_sample)\n",
    "        score = metric(y_sample, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Calculer les percentiles pour l'intervalle de confiance\n",
    "    lower_bound = np.percentile(scores, alpha / 2 * 100)\n",
    "    upper_bound = np.percentile(scores, (1 - alpha / 2) * 100)\n",
    "    return (lower_bound, upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3cc8f5-89e0-4ba0-a495-a0a9587fb178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres à tester\n",
    "rf_params = [{\"n_estimators\": 50, \"max_depth\": 10}, {\"n_estimators\": 100, \"max_depth\": 10},{\"n_estimators\": 50, \"max_depth\": 20},{\"n_estimators\": 100, \"max_depth\": 20},{\"n_estimators\": 200, \"max_depth\": 10},{\"n_estimators\": 200, \"max_depth\": 20}]\n",
    "svm_params = [{\"kernel\": \"poly\", \"C\": 1}, {\"kernel\": \"rbf\", \"C\": 1}, {\"kernel\": \"rbf\", \"C\": 10},{\"kernel\": \"poly\", \"C\": 10},{\"kernel\": \"sigmoid\", \"C\": 1},{\"kernel\": \"sigmoid\", \"C\": 10}]\n",
    "mlp_params = [{\"hidden_layer_sizes\": (50,), \"max_iter\": 300}, {\"hidden_layer_sizes\": (100,), \"max_iter\": 500}]\n",
    "gnb_params = [{'var_smoothing':}]  # GNB n'a pas de paramètres significatifs à varier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4e317-7ddf-4232-8f94-3ccc6d68d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les modèles\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "models_params = {\n",
    "    \"GaussianNB\": (GaussianNB(), gnb_params),\n",
    "    \"SVM\": (SVC(random_state=42), svm_params),\n",
    "    \"RandomForest\": (RandomForestClassifier(random_state=42), rf_params),\n",
    "    \"MLP\": (MLPClassifier(random_state=42), mlp_params),\n",
    "}\n",
    "\n",
    "# Résultats\n",
    "results = {}\n",
    "\n",
    "for model_name, (model, param_list) in models_params.items():\n",
    "    print(f\"Entraînement de {model_name}...\")\n",
    "    results[model_name] = []\n",
    "    for params in param_list:\n",
    "        result = evaluate_model(model, x_train, y_train, x_test, y_test, accuracy_score, params)\n",
    "        result[\"Hyperparameters\"] = params\n",
    "        results[model_name].append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c7570-22d7-4a40-8da4-65badce85011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for model_name, model_results in results.items():\n",
    "    print(f\"\\nRésultats pour {model_name} :\\n\")\n",
    "    df = pd.DataFrame(model_results)\n",
    "    print(df[[\"Hyperparameters\", \"Accuracy\", \"F1-Score\", \"Time (s)\", \"Confidence Interval\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d8054-2003-451a-80ab-9b5a77b1a6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
